{"cells":[{"metadata":{},"cell_type":"markdown","source":"### 1. Preparation & Data Import","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Import required packages","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import KBinsDiscretizer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.dummy import DummyClassifier\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import FunctionTransformer\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import plot_confusion_matrix\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read in training and test data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Rows & Columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape, test_data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Display the first few lines of both","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Sex","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)/len(women)\n\nprint(\"% of women who survived:\", rate_women)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"men = train_data.loc[train_data.Sex == 'male']['Survived']\nrate_men = sum(men)/len(men)\n\nprint(\"% of men who survived:\", rate_men)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Passenger Class","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"first_class = train_data.loc[train_data.Pclass == 1][\"Survived\"]\nrate_first_class = sum(first_class)/len(first_class)\n\nprint(\"% of people in the first class who survived:\", rate_first_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"second_class = train_data.loc[train_data.Pclass == 2][\"Survived\"]\nrate_second_class = sum(second_class)/len(second_class)\n\nprint(\"% of people in the second class who survived:\", rate_second_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"third_class = train_data.loc[train_data.Pclass == 3][\"Survived\"]\nrate_third_class = sum(third_class)/len(third_class)\n\nprint(\"% of people in the third class who survived:\", rate_third_class)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Age","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Dividing Age into four groups to see if there is any correlation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.qcut(train_data['Age'],4).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Survived'].groupby(pd.qcut(train_data['Age'], 4)).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Heatmaps - Correlation of independent variables with Survivability","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6, 9))\nheatmap = sns.heatmap(train_data.corr()[['Survived']].sort_values(by='Survived', ascending=False), vmin=-1, vmax=1, annot=True, cmap='YlGnBu')\n\nheatmap.set_title('Variables Correlating with Survivability', fontdict={'fontsize':12}, pad=16);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(9, 9))\nheatmap = sns.heatmap(train_data.corr(), vmin=-1, vmax=1, annot=True, cmap='YlGnBu')\n\nheatmap.set_title('Correlating Variables', fontdict={'fontsize':12}, pad=16);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Imputation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Display missing values in both the test and training data set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isna().sum(), test_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Filling in missing values of Age with Median","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"age_median = train_data['Age'].median()\nage_median","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Age'].fillna(age_median, inplace = True)\ntest_data['Age'].fillna(age_median, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Display rows with missing values in 'Embarked'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[train_data['Embarked'].isna() == True]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Look for similar Rows and take a majority vote on what to put into the missing values for 'Embarked'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[(train_data['Survived'] == 1) & (train_data['Pclass'] == 1) & (train_data['Sex'] == 'female') & (train_data['SibSp'] == 0) & (train_data['Parch'] == 0)].sort_values(by=['Fare'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embarked_nn_mode = train_data[(train_data['Survived'] == 1) & (train_data['Pclass'] == 1) & (train_data['Sex'] == 'female') & (train_data['SibSp'] == 0) & (train_data['Parch'] == 0)].sort_values(by=['Fare'])['Embarked'].mode()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embarked_nn_mode","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fill in the missing values for 'Embarked'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Embarked'].fillna('C', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Display rows with missing values in 'Fare'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data[test_data['Fare'].isna() == True]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Look for similar Rows and take a majority vote on what to put into 'Fare'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fare_nn_median = test_data[(test_data['Pclass'] == 3) & (test_data['Sex'] == 'male') & (test_data['SibSp'] == 0) & (test_data['Parch'] == 0)].sort_values(by=['Fare'])['Fare'].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fare_nn_median","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['Fare'].fillna(fare_nn_median, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cabin - Missing Values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Cabin'].fillna('0', inplace = True)\ntest_data['Cabin'].fillna('0', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Final check for missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isna().sum(), test_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Feature Engineering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Defining features & converting them to indicator values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# def extract_second_position_from_id(df):  # input is a DataFrame (with 1 column)\n#    \"\"\"Returns the second position of a string column\"\"\"\n#    first_char = df.iloc[:, 0].str[1].astype(int)\n#    return first_char.values.reshape(-1, 1) # output has to be a 2D matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# trans = ColumnTransformer([\n#    ('my_id', FunctionTransformer(extract_second_position_from_id), ['Individual ID']),    \n#    ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'), ['Island', 'Sex']),\n#    ('my_binning', KBinsDiscretizer(n_bins=5, encode='onehot', strategy='quantile'), ['Culmen Depth (mm)']),   # like pd.qcut()\n#    ('do_nothing', 'passthrough', ['Pclass'])\n#    ])\n#\n# , 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked'\n#\n# trans.fit(train_data)\n# X_train = trans.transform(train_data)\n# X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# p = make_pipeline(\n#    trans,\n#    MinMaxScaler(),\n#    RandomForestClassifier()\n#)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# p.fit(X_train, y_train)\n# p.score(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Name']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Name_Length'] = train_data['Name'].apply(lambda x: len(x))\ntrain_data['Survived'].groupby(pd.qcut(train_data['Name_Length'],3)).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.qcut(train_data['Name_Length'], 3).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"name_cut_labels = ['short', 'medium', 'long']\ntrain_data['Name_Length'] = pd.qcut(train_data['Name_Length'], 3, labels = name_cut_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Name_Length'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['Name_Length'] = test_data['Name'].apply(lambda x: len(x))\ntest_data['Name_Length'] = pd.cut(test_data['Name_Length'], 3, labels = name_cut_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Fare","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Survived'].groupby(pd.qcut(train_data['Fare'], 4)).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.qcut(train_data['Fare'], 4).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fare_cut_labels = ['0', '1', '2', '3']\ntrain_data['Fare'] = pd.qcut(train_data['Fare'], q=4, labels = fare_cut_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Fare'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['Fare'] = pd.qcut(test_data['Fare'], q=4, labels = fare_cut_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Cabin First Letter / Deck","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Deck'] = train_data['Cabin'].apply(lambda x: str(x)[0])\ntest_data['Deck'] = test_data['Cabin'].apply(lambda x: str(x)[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Deck'] = train_data['Deck'].apply(lambda x: 0 if x == \"0\" else 1)\ntest_data['Deck'] = test_data['Deck'].apply(lambda x: 0 if x == \"0\" else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Deck'].value_counts(), train_data['Deck'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Deck']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Normalize Age","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"age_range = train_data['Age'].max() - train_data['Age'].min()\nage_range","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Age_normalized'] = ( train_data['Age'] - train_data['Age'].min() ) / age_range\ntest_data['Age_normalized'] = ( test_data['Age'] - test_data['Age'].min() ) / age_range","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Age_normalized'], test_data['Age_normalized']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Normalize Pclass","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaler = MinMaxScaler()\n# scaler.fit(train_data[['Pclass']].reshape(-1, 1))\n# print(scaler.transform(train_data[['Pclass']].reshape(-1, 1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['Pclass', 'Sex', 'Age_normalized', 'SibSp', 'Parch', 'Embarked', 'Deck', 'Name_Length', 'Fare']\nX_train = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\nprint(X_train)\nprint(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Heatmaps - Correlation of independent variables with Survivability","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['Pclass', 'Sex', 'Age_normalized', 'SibSp', 'Parch', 'Embarked', 'Fare', 'Survived', 'Deck', 'Name_Length']\nX_heat = pd.get_dummies(train_data[features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6, 9))\n\nheatmap = sns.heatmap(X_heat.corr()[['Survived']].sort_values(by='Survived', ascending=False), vmin=-1, vmax=1, annot=True, cmap='YlGnBu')\nheatmap.set_title('Features Correlating with Survivability', fontdict={'fontsize':12}, pad=16);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. Creating model(s)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define y for the training data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train_data['Survived']\ny_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Creating Baseline Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_BL = DummyClassifier(strategy='most_frequent', random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_BL.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Logistic Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_LR = LogisticRegression(random_state=23)\nmodel_LR.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_DT = DecisionTreeClassifier(max_depth=7, min_samples_split=2, random_state=23)\nmodel_DT.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_RF = RandomForestClassifier(n_estimators=900, max_depth=7, min_samples_split=10, random_state=23)\nmodel_RF.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 6. Model predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_BL = model_BL.predict(X_train)\npredictions_LR = model_LR.predict(X_train)\npredictions_DT = model_DT.predict(X_train)\npredictions_RF = model_RF.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 7. Model Performance","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Baseline Performance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_train, predictions_BL))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_BL, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Logistic Regression Performance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_train, predictions_LR))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_LR, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Decision Tree Performance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_train, predictions_DT))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_DT, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Random Forest Performance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_train, predictions_RF))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_confusion_matrix(model_RF, X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8. Hyperparameter Optimization / Cross Validation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Defining Hyperparameters for the Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"hyperparams_DT = {\n    'max_depth': list(range(2, 9)), \n    'min_samples_split': list(range(2, 20, 2))\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating an estimator for Decision Tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"g = GridSearchCV(model_DT, hyperparams_DT, cv=5)\ng.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Show me the best parameters for the Decision Tree model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"g.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining Hyperparameters for the Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"hyperparams_RF = {\n    'max_depth': list(range(3, 8)), \n    'min_samples_split': list(range(5, 31, 5)),\n    'n_estimators': list(range(900, 1001, 100))\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating an estimator for Random Forest","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"g = GridSearchCV(model_RF, hyperparams_RF, cv=5, verbose=1, n_jobs=-1)\ng.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Show me the best parameters for the Random Forest model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"g.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 9. Formatting for Export","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model_RF.predict(X_test)\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}