{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from credentials import cid, secret, username, password\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import time\n",
    "import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "client_credentials_manager = spotipy.oauth2.SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager\n",
    "                     = client_credentials_manager)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Setting up database connection with Mongo DB"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "client = pymongo.MongoClient(\"mongodb://localhost/\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "db_mongo = client.song_data\n",
    "songs_info = db_mongo.techno_info\n",
    "songs_features = db_mongo.techno_features\n",
    "songs_analysis = db_mongo.techno_analysis\n",
    "analysis_bad_ids = db_mongo.bad_ids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Get artists by genre\n",
    "artists = pd.DataFrame()\n",
    "search_string = 'genre:\"techno\"'\n",
    "for i in tqdm.tqdm(range(0,2000,50)):\n",
    "    artists = artists.append(sp.search(search_string, limit=50, offset=i, type='artist', market=\"DE\"), ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Get albums from Artists\n",
    "albums = pd.DataFrame()\n",
    "for z in tqdm.tqdm(range(len(artists))):\n",
    "    for i in range(len(artists.iloc[z][\"artists\"][\"items\"])):\n",
    "        albums = albums.append(sp.artist_albums(artists.iloc[z][\"artists\"][\"items\"][i][\"id\"], limit=50), ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Get tracks from each album\n",
    "songs = pd.DataFrame()\n",
    "for z in tqdm.tqdm(range(len(albums))):\n",
    "    for i in range(len(albums.iloc[z][\"items\"])):\n",
    "        songs = songs.append(sp.album_tracks(albums.iloc[z][\"items\"][i][\"id\"], limit=100), ignore_index=True)\n",
    "songs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Get Song Ids from database\n",
    "info_ids = []\n",
    "query = songs_info.find({}, {\"_id\": 0, \"id\": 1})\n",
    "for id in query:\n",
    "    info_ids += id.values()\n",
    "print(len(info_ids))\n",
    "\n",
    "feature_ids = []\n",
    "query = songs_features.find({}, {\"_id\": 0, \"id\": 1})\n",
    "for id in query:\n",
    "    feature_ids += id.values()\n",
    "print(len(feature_ids))\n",
    "\n",
    "analysis_ids = []\n",
    "query = songs_analysis.find({}, {\"_id\": 0, \"id\": 1})\n",
    "for id in query:\n",
    "    analysis_ids += id.values()\n",
    "print(len(analysis_ids))\n",
    "\n",
    "bad_ids = []\n",
    "query = analysis_bad_ids.find({}, {\"_id\": 0, \"id\": 1})\n",
    "for id in query:\n",
    "    bad_ids += id.values()\n",
    "print(len(bad_ids))\n",
    "\n",
    "final_ids_features = list(set(info_ids) - set(feature_ids))\n",
    "print(len(final_ids_features))\n",
    "final_ids_analysis = list(set(feature_ids) - set(analysis_ids) - set(bad_ids))\n",
    "print(len(final_ids_analysis))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#Get song infos and write it in a mongoDB collection\n",
    "info_df = pd.DataFrame()\n",
    "print(len(set(song_ids)))\n",
    "for i in range(0, len(set(song_ids)), 50):\n",
    "    temp_ids = []\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    for id in set(song_ids[i:i+50]):\n",
    "        temp_ids += [id]\n",
    "    info_df = info_df.append(sp.tracks(temp_ids, market=\"DE\")[\"tracks\"], ignore_index=True)\n",
    "\n",
    "songs_info.insert_many(info_df.to_dict('records'))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Get song features and write it in a mongoDB collection\n",
    "\n",
    "features_dict = []\n",
    "features_df = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(final_ids_features), 100):\n",
    "    temp_ids = []\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    for id in final_ids_features[i:i+100]:\n",
    "        temp_ids += [id]\n",
    "    features_dict.append(sp.audio_features(temp_ids))\n",
    "print(features_dict)\n",
    "\n",
    "print(\"All features data collected\")\n",
    "\n",
    "for i in range(len(features_dict)):\n",
    "    for z in features_dict[i]:\n",
    "        if z == None:\n",
    "            features_dict[i].remove(z)\n",
    "\n",
    "for i in features_dict:\n",
    "    features_df = features_df.append(i)\n",
    "\n",
    "songs_features.insert_many(features_df.to_dict('records'));\n",
    "\n",
    "print(\"All features data written in database\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove duplicates from Database\n",
    "feature_df = pd.DataFrame()\n",
    "feature_df = pd.DataFrame(list(songs_features.find()))\n",
    "feature_df.drop_duplicates(\"id\", inplace=True)\n",
    "songs_features.insert_many(feature_df.to_dict('records'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17908it [2:44:39,  2.65it/s]Max Retries reached\n",
      "17943it [2:44:59,  2.97it/s]Max Retries reached\n",
      "17977it [2:45:17,  3.14it/s]Max Retries reached\n",
      "18085it [2:46:08,  2.80it/s]Max Retries reached\n",
      "18138it [2:46:36,  2.84it/s]Max Retries reached\n",
      "18173it [2:46:58,  2.72it/s]Max Retries reached\n",
      "18212it [2:47:26,  2.31it/s]Max Retries reached\n",
      "18216it [2:47:33,  1.02it/s]Max Retries reached\n",
      "18397it [2:48:50,  2.79it/s]Max Retries reached\n",
      "18554it [2:50:01,  3.10it/s]Max Retries reached\n",
      "18577it [2:50:16,  2.06it/s]Max Retries reached\n",
      "18578it [2:50:22,  2.01s/it]Max Retries reached\n",
      "18647it [2:51:01,  2.60it/s]Max Retries reached\n",
      "18802it [2:52:05,  2.15it/s]Max Retries reached\n",
      "18818it [2:52:18,  2.58it/s]Max Retries reached\n",
      "18873it [2:52:44,  2.65it/s]Max Retries reached\n",
      "18884it [2:52:53,  2.93it/s]Max Retries reached\n",
      "18905it [2:53:09,  3.23it/s]Max Retries reached\n",
      "18928it [2:53:25,  2.04it/s]Max Retries reached\n",
      "18941it [2:53:40,  1.96it/s]Max Retries reached\n",
      "18996it [2:54:07,  2.30it/s]Max Retries reached\n",
      "19064it [2:54:40,  2.42it/s]Max Retries reached\n",
      "19142it [2:55:16,  2.53it/s]Max Retries reached\n",
      "19180it [2:55:39,  2.19it/s]Max Retries reached\n",
      "19185it [2:55:47,  1.29it/s]Max Retries reached\n",
      "19267it [2:56:28,  2.69it/s]Max Retries reached\n",
      "19325it [2:56:58,  2.72it/s]Max Retries reached\n",
      "19345it [2:57:10,  2.37it/s]Max Retries reached\n",
      "19356it [2:57:21,  2.66it/s]Max Retries reached\n",
      "19386it [2:57:37,  3.08it/s]Max Retries reached\n",
      "19427it [2:58:00,  2.18it/s]Max Retries reached\n",
      "19431it [2:58:07,  1.05s/it]Max Retries reached\n",
      "19496it [2:58:40,  2.58it/s]Max Retries reached\n",
      "19593it [2:59:27,  2.12it/s]Max Retries reached\n",
      "19656it [3:00:05,  2.59it/s]Max Retries reached\n",
      "19661it [3:00:18,  1.16s/it]Max Retries reached\n",
      "19662it [3:00:24,  2.53s/it]Max Retries reached\n",
      "19689it [3:00:38,  2.26it/s]Max Retries reached\n",
      "19729it [3:01:01,  2.31it/s]Max Retries reached\n",
      "19749it [3:01:15,  3.33it/s]Max Retries reached\n",
      "19760it [3:01:24,  2.36it/s]Max Retries reached\n",
      "19856it [3:02:24,  1.04s/it]"
     ]
    }
   ],
   "source": [
    "#Get song analysis and write it in a mongoDB collection\n",
    "analysis_df = pd.DataFrame()\n",
    "i = 0\n",
    "for z, id in tqdm.tqdm(enumerate(final_ids_analysis)):\n",
    "    try:\n",
    "        analysis_df = analysis_df.append(sp.audio_analysis(id)[\"track\"], ignore_index=True)\n",
    "        analysis_df.drop(['analysis_channels', 'analysis_sample_rate', 'code_version',\n",
    "           'codestring', 'echoprint_version', 'echoprintstring', 'rhythm_version',\n",
    "           'rhythmstring', 'sample_md5', 'synch_version',\n",
    "           'synchstring'], axis=1, inplace=True)\n",
    "        analysis_df.loc[i ,\"id\"] = id\n",
    "        if i == 1000:\n",
    "            songs_analysis.insert_many(analysis_df.to_dict('records'))\n",
    "            analysis_df = pd.DataFrame()\n",
    "            i = 0\n",
    "        else:\n",
    "            i += 1\n",
    "    except:\n",
    "        analysis_bad_ids.insert_one({\"id\":id, \"time\":time.time()})\n",
    "        pass\n",
    "\n",
    "print(\"All analysis data collected and written in database\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}