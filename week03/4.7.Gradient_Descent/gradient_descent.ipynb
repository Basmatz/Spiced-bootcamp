{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "\n",
    "#coefficients\n",
    "b = -1.5\n",
    "w_1 = 2.0\n",
    "\n",
    "np.random.normal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(size=sample_size) #create x values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= b + w_1 * x + np.random.normal(size= sample_size) #create y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_line(x,slope,intercept) :\n",
    "    ypred= intercept + slope * x\n",
    "    return ypred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = make_line(x,w_1,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we plot the actual data and the line together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y)\n",
    "plt.plot(x,ypred,color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##our machine learning algorithm does not know the true relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y)\n",
    "plt.plot(x,make_line(x,-3.0,2.0),color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the size of the plots\n",
    "plt.rcParams['figure.figsize'] = (12,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that calculates the mean squarred error\n",
    "def mse(ytrue,ypred) :\n",
    "    error= np.mean((ytrue-ypred)**2)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse(y,make_line(x,-3.0,2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y,make_line(x,-3.0,2.0)) #of course, they have the same value !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the function\n",
    "a = np.array([1.0,1.2,1.4,1.6])\n",
    "b = np.array([0.2,0.4,0.6,0.8])\n",
    "\n",
    "assert round(mse(a,b),2)==0.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function that approximates the gradient\n",
    "def calc_gradient(x, ytrue, slope, intercept):\n",
    "\n",
    "    # Infinitessimal small change applied to each parameter\n",
    "    dw = 0.0001\n",
    "    \n",
    "    ypred = make_line(x, slope, intercept)\n",
    "\n",
    "    '''tweak first parameter'''\n",
    "    slope_change = slope + dw\n",
    "    # calculate predictions using intercept and slope_change\n",
    "    ypred_slope = make_line(x, slope_change, intercept)\n",
    "    deriv_slope = (mse(ytrue, ypred_slope) - mse(ytrue, ypred)) / dw\n",
    "\n",
    "    '''tweak second parameter'''\n",
    "    intercept_change = intercept + dw\n",
    "    # calculate predictions using intercept_change and slope\n",
    "    ypred_intercept = make_line(x, slope, intercept_change)\n",
    "    deriv_intercept = (mse(ytrue, ypred_intercept) - mse(ytrue, ypred)) / dw\n",
    "\n",
    "    return [deriv_slope, deriv_intercept] # return both derivations as a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLOPE = -1.0 # arbitrary starting value\n",
    "INTERCEPT = 5.0 # arbitrary starting value\n",
    "LR = 0.1 # choose a small learning rate\n",
    "MAX_ITER = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range (MAX_ITER):\n",
    "\n",
    "#1. In each iteration of the loop, calculate the gradient of your loss function with respect to each model parameter.\n",
    "    gradient = calc_gradient(x, y, SLOPE, INTERCEPT)\n",
    " \n",
    "#2. For each model parameter, multiply the corresponding partial derivative by the learning rate, then negate it.\n",
    "    update_slope = -LR*gradient[0]\n",
    "    update_intercept = -LR*gradient[1]\n",
    "\n",
    "#3. Add the resulting product to the previous value of the model parameter to get the updated parameter value.\n",
    "#4. Overwrite the values of each parameter with its updated value.\n",
    "    SLOPE = SLOPE + update_slope\n",
    "    INTERCEPT = INTERCEPT + update_intercept\n",
    "\n",
    "#5. Print all variables as you loop to make sure your parameters are converging to their expected values.\n",
    "    print(f'The slope after iteration {iteration} is {SLOPE}')\n",
    "    print(f'The intercept after iteration {iteration} is {INTERCEPT}')\n",
    "\n",
    "#6. Repeat the above steps `MAX_ITER` times.\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot(x, make_line(x, SLOPE, INTERCEPT))\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    time.sleep(0.0001)\n",
    "\n",
    "#7. If the gradient becomes smaller than some pre-determined small threshold value, break out of the loop.\n",
    "    if abs(gradient[0]) < 0.01 or abs(gradient[1]) < 0.01:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# result \n",
    "try some learning rates and look at the performance of gradient descent. And decide which one is best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
