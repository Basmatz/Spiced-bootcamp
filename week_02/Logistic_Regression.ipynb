{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "## 0) Warmup\n",
    "\n",
    "1. What are we trying to predict in this weeks project?\n",
    "- Which values does y take on?\n",
    "- What information do we use to make the prediction?\n",
    "\n",
    "## 1) Predicting Probabilities\n",
    "\n",
    "Instead of directly predicting the binary outcome (0, 1), we are actually predicting a probability of \"success\" (belonging to class 1).\n",
    "\n",
    "$f(X) = \\hat{p}(X)$\n",
    "\n",
    "where X are input features such as *age*, *Pclass*, *gender*, ...\n",
    "\n",
    "How do we do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Threshold value of 0.5\n",
    "- The parameters are responsible for the predictions\n",
    "    - w are the weights of the input features --> determine the sensitivity of the curve\n",
    "    - b is a parameter that shifts the function to the left (>0) or right (<0). It determines the predicted probability for x=0\n",
    "- How do we find the parameters? --> The loss is minimized --> Every machine learning algorithm will have some kind of loss (objective functin) that is minimized.\n",
    "- The minimzation of the loss is equivalent to the maximization of the likelihood of observing the data points that we have observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Let's do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Import logistic regression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    608\n",
       "1    209\n",
       "2     28\n",
       "4     18\n",
       "3     16\n",
       "8      7\n",
       "5      5\n",
       "Name: SibSp, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "df = pd.read_csv(\"train.csv\", index_col=0)\n",
    "df[\"SibSp\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X\n",
    "#Try Passenger class - turn Series into dataframe - sklearn does not work with Series\n",
    "\n",
    "X= df[[\"Pclass\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y\n",
    "# Must be a Series for sklearn\n",
    "y = df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and a test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y) \n",
    "#By default it splits the data 75-25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "\n",
    "m = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a model\n",
    "\n",
    "m.fit(X_train, y_train) # <-- whole iterative process of finding parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.80907802])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the parameter coefficients?\n",
    "w = m.coef_[0] \n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.40767376])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b= m.intercept_\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the model to make predictions on the seen data\n",
    "\n",
    "#ypred_train = m.predict(X_train)\n",
    "ypred_test = m.predict(X_test) # <-- the predicted y values\n",
    "\n",
    "ypred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.55242716, 0.44757284],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.73488694, 0.26511306],\n",
       "       [0.35466503, 0.64533497],\n",
       "       [0.35466503, 0.64533497]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict_proba(X_test)  # <-- the probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the long run, we want to use more than one predictor (X-variable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi = df.dropna(subset=[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_multi = df_multi[['Pclass', 'Age']]\n",
    "y_multi = df_multi['Survived']\n",
    "# Can then use m.fit - here skipping the train-test split\n",
    "\n",
    "m.fit(X_multi, y_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.22653571, -0.04149665]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.696078431372549"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy - which ratio of the data points were classified corectly?\n",
    "m.score(X_multi, y_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
